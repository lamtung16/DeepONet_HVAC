{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "jzH_LbEIGLWu"
      },
      "outputs": [],
      "source": [
        "# library\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torchmetrics import R2Score, MeanSquaredError\n",
        "import csv\n",
        "\n",
        "r2score  = R2Score()\n",
        "msescore = MeanSquaredError()\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "torch.set_printoptions(precision=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Y3eaKBL2GhJI"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, n=4, p=8, noi=1, b0_size = 8, bi_size = 2, trunk_size = 8):\n",
        "    super(Net, self).__init__()\n",
        "    self.n   = n                    # horizon window length\n",
        "    self.p   = p                    # size of branch and trunk output\n",
        "    self.noi = noi                  # number of input\n",
        "\n",
        "    self.b0_size    = b0_size\n",
        "    self.bi_size    = bi_size\n",
        "    self.trunk_size = trunk_size\n",
        "    \n",
        "    # Branch x0\n",
        "    self.input_x0  = torch.nn.Linear(1, self.b0_size)\n",
        "    self.hidden_x0 = torch.nn.Linear(self.b0_size, self.b0_size)\n",
        "    self.output_x0 = torch.nn.Linear(self.b0_size, self.p)\n",
        "\n",
        "    # Branch 1 u\n",
        "    self.input_u  = torch.nn.Linear(self.noi*self.n, self.bi_size)\n",
        "    self.hidden_u = torch.nn.Linear(self.bi_size, self.bi_size)\n",
        "    self.output_u = torch.nn.Linear(self.bi_size, self.p)\n",
        "\n",
        "    # Trunk\n",
        "    self.input_t  = torch.nn.Linear(1, self.trunk_size)\n",
        "    self.hidden_t = torch.nn.Linear(self.trunk_size, self.trunk_size)\n",
        "    self.output_t = torch.nn.Linear(self.trunk_size, self.p)\n",
        "\n",
        "  def forward(self, x0, u, t):\n",
        "    # h\n",
        "    h = torch.selu(self.input_x0(x0))\n",
        "    h = torch.selu(self.hidden_x0(h))\n",
        "    h = self.output_x0(h)\n",
        "\n",
        "    # f\n",
        "    f = torch.selu(self.input_u(u))\n",
        "    f = torch.selu(self.hidden_u(f))\n",
        "    f = self.output_u(f)\n",
        "\n",
        "    # g\n",
        "    g = torch.selu(self.input_t(t))\n",
        "    g = torch.selu(self.hidden_t(g))\n",
        "    g = self.output_t(g)\n",
        "\n",
        "    return torch.sum(h*f*g, dim=1).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "BtNtb3epPIzJ"
      },
      "outputs": [],
      "source": [
        "# Model error\n",
        "def eval(model, testset):\n",
        "    with torch.no_grad():\n",
        "        pred_Y = model(testset.x0_data, testset.u_data, testset.t_data)\n",
        "\n",
        "    r2_1  = r2score(pred_Y[0::4], testset.y_data[0::4])\n",
        "    mse_1 = msescore(pred_Y[0::4], testset.y_data[0::4])\n",
        "    r2_2  = r2score(pred_Y[1::4], testset.y_data[1::4])\n",
        "    mse_2 = msescore(pred_Y[1::4], testset.y_data[1::4])\n",
        "    r2_3  = r2score(pred_Y[2::4], testset.y_data[2::4])\n",
        "    mse_3 = msescore(pred_Y[2::4], testset.y_data[2::4])\n",
        "    r2_4  = r2score(pred_Y[3::4], testset.y_data[3::4])\n",
        "    mse_4 = msescore(pred_Y[3::4], testset.y_data[3::4])\n",
        "    return r2_1.item(), mse_1.item(), r2_2.item(), mse_2.item(), r2_3.item(), mse_3.item(), r2_4.item(), mse_4.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "dTWtNEdVHCuw"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "class Data(torch.utils.data.Dataset):\n",
        "  def __init__(self, src_file, n, H, noi):\n",
        "    self.n   = n                                  # horizon length\n",
        "    self.H   = H                                  # max window length\n",
        "    self.noi = noi                                # number of input\n",
        "    self.src_file = src_file                      # source file\n",
        "    df = pd.read_csv(self.src_file, header=None)\n",
        "\n",
        "    X0, U, T, Y = np.array([[1]], dtype=np.float32), np.ones((1, n*self.noi)), np.array([[1]], dtype=np.float32), np.array([[1]], dtype=np.float32)\n",
        "    for i in range(df.shape[0]):\n",
        "        row = np.array(df.iloc[i])\n",
        "        for j in range(self.H - self.n):\n",
        "            x0 = np.array([[row[self.H*self.noi + j]]])\n",
        "            u  = np.array([row[j:j + self.n*self.noi]])\n",
        "            for t in range(1, self.n + 1):\n",
        "                y = np.array([[row[self.H*self.noi + j + t]]])\n",
        "                t = np.array([[t]])\n",
        "\n",
        "                X0 = np.concatenate((X0, x0))\n",
        "                U  = np.concatenate((U, u))\n",
        "                T  = np.concatenate((T, t))\n",
        "                Y  = np.concatenate((Y, y))\n",
        "\n",
        "    X0, U, T, Y = X0[1:], U[1:], T[1:], Y[1:]\n",
        "\n",
        "    self.x0_data = torch.tensor(X0, dtype=torch.float32)\n",
        "    self.u_data  = torch.tensor(U,  dtype=torch.float32)\n",
        "    self.t_data  = torch.tensor(T,  dtype=torch.float32)\n",
        "    self.y_data  = torch.tensor(Y,  dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x0_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    x0  = self.x0_data[idx]\n",
        "    u   = self.u_data[idx]\n",
        "    t   = self.t_data[idx]\n",
        "    y   = self.y_data[idx]\n",
        "    sample = {'x0':x0, 'u':u, 't':t, 'y':y}\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Early stopping\n",
        "def early_stop(list, min_epochs, patience):\n",
        "    if(len(list) > min_epochs):\n",
        "        if(np.max(list[-patience:]) < 1.0001*np.max(list[0: -patience])):\n",
        "            return 1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot\n",
        "def plot(net, dataset, size):\n",
        "    with torch.no_grad():\n",
        "        pred_Y = net(dataset.x0_data, dataset.u_data, dataset.t_data)\n",
        "\n",
        "    plt.figure(figsize=size)\n",
        "    plt.plot(dataset.y_data[0::4], 'b',   label=r'real',      linewidth=3)\n",
        "    plt.plot(pred_Y[0::4],         'r--', label=r'predicted', linewidth=1)\n",
        "    plt.ylabel(r'x(t)')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train function\n",
        "def train(net, train_ds, test_ds, min_epochs=200, max_epochs=100000, patience=100):\n",
        "    loss_func  = torch.nn.MSELoss()\n",
        "    optimizer  = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    train_ldr = torch.utils.data.DataLoader(train_ds, batch_size=train_ds.y_data.shape[0], shuffle=True)\n",
        "\n",
        "    R2  = np.array([])\n",
        "    MSE = np.array([])\n",
        "    for epoch in range(0, max_epochs+1):\n",
        "        net.train()\n",
        "        loss  = 0\n",
        "        count = 0\n",
        "        for (_, batch) in enumerate(train_ldr):\n",
        "            X0 = batch['x0']\n",
        "            U  = batch['u']\n",
        "            T  = batch['t']\n",
        "            Y  = batch['y']\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(X0, U, T)             # compute the output of the Network\n",
        "            loss_val = loss_func(output, Y)    # loss function\n",
        "            loss += loss_val.item()            # accumulate\n",
        "            loss_val.backward()                # gradients\n",
        "            optimizer.step()                   # update paramters\n",
        "            count += 1\n",
        "        \n",
        "        net.eval()\n",
        "        R2_1  = np.append(R2, eval(net, test_ds)[0])\n",
        "        MSE_1 = np.append(MSE, eval(net, test_ds)[1])\n",
        "        R2_2  = np.append(R2, eval(net, test_ds)[2])\n",
        "        MSE_2 = np.append(MSE, eval(net, test_ds)[3])\n",
        "        R2_3  = np.append(R2, eval(net, test_ds)[4])\n",
        "        MSE_3 = np.append(MSE, eval(net, test_ds)[5])\n",
        "        R2_4  = np.append(R2, eval(net, test_ds)[6])\n",
        "        MSE_4 = np.append(MSE, eval(net, test_ds)[7])\n",
        "        \n",
        "        if(early_stop(list = R2, min_epochs = min_epochs, patience = patience) == 1):\n",
        "            break\n",
        "    \n",
        "    return R2_1, MSE_1, R2_2, MSE_2, R2_3, MSE_3, R2_4, MSE_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('stat_original.csv', 'w') as file:\n",
        "     writer = csv.writer(file)\n",
        "     writer.writerow(['p', 'b0', 'bi', 'trunk', 'R2_1', 'MSE_1', 'R2_2', 'MSE_2', 'R2_3', 'MSE_3', 'R2_4', 'MSE_4'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gebr4CnRLFBd",
        "outputId": "d74e7cd7-8dab-49a9-babc-e77577dd73b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 4 2 4 -499.6763916015625 1585.557373046875 -516.3147583007812 1643.5946044921875 -552.5969848632812 1766.7698974609375 -643.6036987304688 2065.142822265625\n",
            "4 4 2 8 -1626.4930419921875 5153.9951171875 -1624.177490234375 5163.45751953125 -1618.4967041015625 5168.521484375 -1613.1136474609375 5171.20068359375\n",
            "4 4 8 4 -18219.80859375 57702.21484375 -12880.5263671875 40926.73828125 -9879.7646484375 31533.837890625 -7294.45849609375 23372.75390625\n",
            "4 4 8 8 -1275.292724609375 4041.80322265625 -1197.5587158203125 3808.019287109375 -1221.8734130859375 3902.723388671875 -1267.8443603515625 4065.0478515625\n",
            "4 8 2 4 -3534.916015625 11197.6474609375 -5804.04541015625 18443.587890625 -8353.96484375 26664.34375 -11147.9931640625 35718.4765625\n",
            "4 8 2 8 -1278.7371826171875 4052.711181640625 -1240.6412353515625 3944.899658203125 -1187.62353515625 3793.417236328125 -1136.2911376953125 3643.585205078125\n",
            "4 8 8 4 -486.31298828125 1543.2376708984375 -64.16004180908203 207.02423095703125 -150.71522521972656 484.1896057128906 -241.8491973876953 778.0256958007812\n",
            "4 8 8 8 -15382.9599609375 48718.3984375 -3330.1748046875 10583.693359375 -3771.546875 12039.845703125 -5841.900390625 18719.134765625\n",
            "8 4 2 4 -1200.0250244140625 3803.44287109375 -740.105712890625 2354.615478515625 -458.0871887207031 1465.1478271484375 -422.867431640625 1357.961181640625\n",
            "8 4 2 8 -1627.8355712890625 5158.24658203125 -1619.85546875 5149.72607421875 -1610.3155517578125 5142.412109375 -1602.5458984375 5137.3447265625\n",
            "8 4 8 4 -5720.4482421875 18118.857421875 -4416.76416015625 14035.966796875 -3898.090087890625 12443.701171875 -3752.62060546875 12025.625\n",
            "8 4 8 8 -853.4663696289062 2705.9501953125 -694.15576171875 2208.624755859375 -611.0394897460938 1953.2855224609375 -511.70574951171875 1642.5760498046875\n",
            "8 8 2 4 -160527.890625 508367.84375 -20722.2421875 65841.1640625 -2675.792236328125 8542.814453125 -40038.76171875 128276.9921875\n",
            "8 8 2 8 -8390.8583984375 26575.59375 -9555.169921875 30361.53125 -9744.8359375 31103.220703125 -9915.48828125 31769.8515625\n",
            "8 8 8 4 -1878.3876953125 5951.70263671875 -13659.7705078125 43402.52734375 -31128.767578125 99348.6953125 -51866.359375 166169.546875\n",
            "8 8 8 8 -8616.072265625 27288.80859375 -18252.23828125 57993.55859375 -27123.8828125 86567.3515625 -35368.6953125 113315.3046875\n"
          ]
        }
      ],
      "source": [
        "df_result = pd.DataFrame({'p':[], 'b0':[], 'bi':[], 'trunk':[], 'R2_1':[], 'MSE_1':[], 'R2_2':[], 'MSE_2':[], 'R2_3':[], 'MSE_3':[], 'R2_4':[], 'MSE_4':[]})\n",
        "\n",
        "for _p in [4, 8]:\n",
        "    for b0 in [4, 8]:\n",
        "        for bi in [2, 8]:\n",
        "            for trunk in [4, 8]:\n",
        "                # Hyperparameters\n",
        "                p   = _p          # size of branch and trunk ouput\n",
        "                n   = 4           # horizon window length\n",
        "                noi = 2           # number of inputs\n",
        "                H   = 512         # maximum window length\n",
        "\n",
        "                # Create Dataset and DataLoader objects\n",
        "                src_file_train = '0. Data/data_0.csv'\n",
        "                train_ds       = Data(src_file_train, n, H, noi)\n",
        "\n",
        "                src_file_test  = '0. Data/data_1.csv'\n",
        "                test_ds        = Data(src_file_test, n, H, noi)\n",
        "\n",
        "                # Create network\n",
        "                device = torch.device(\"cpu\")\n",
        "                net = Net(n, p, noi, b0_size=b0, bi_size=bi, trunk_size=trunk).to(device)\n",
        "\n",
        "                # train model\n",
        "                min_epochs = 2\n",
        "                max_epochs = 3\n",
        "                patience   = 1\n",
        "                R2_1, MSE_1, R2_2, MSE_2, R2_3, MSE_3, R2_4, MSE_4 = train(net, train_ds, test_ds, min_epochs, max_epochs, patience)\n",
        "\n",
        "                with open('stat_original.csv', 'a') as file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow([_p, b0, bi, trunk, np.max(R2_1), np.min(MSE_1), np.max(R2_2), np.min(MSE_2), np.max(R2_3), np.min(MSE_3), np.max(R2_4), np.min(MSE_4)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3. T_z .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "912d6611990680b3d240e982c9d50f3da4c776707cfd42695cf7d82c88d80956"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
